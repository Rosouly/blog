<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - My New Hugo Site</title>
        <link>https://rosouly.github.io/rosy.github.io/posts/</link>
        <description>All Posts | My New Hugo Site</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 03 Sep 2023 14:44:43 &#43;0800</lastBuildDate><atom:link href="https://rosouly.github.io/rosy.github.io/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Go Zero从入门到k8s部署</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/go-zero%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0k8s%E9%83%A8%E7%BD%B2/</link>
    <pubDate>Sun, 03 Sep 2023 14:44:43 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/go-zero%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0k8s%E9%83%A8%E7%BD%B2/</guid>
    <description><![CDATA[详情见：https://www.remnote.com/a/go-zerok8s/64f42704e689a049784efaeb]]></description>
</item>
<item>
    <title>K8s</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/k8s/</link>
    <pubDate>Thu, 31 Aug 2023 07:36:53 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/k8s/</guid>
    <description><![CDATA[任务一 成果：在浏览器分别访问 http://&lt;k8s节点1的ip&gt;/30000.com 和 http://&lt;k8s节点2的ip&gt;/30000.com 显示 [v1] Hello, Kubernetes!
前言：本次任务将涉及两个概念，一个是pod，一个是service。同时将会提供两个yaml文件，达到成果后，想办法请搞清楚这两个文件每一行的的含义，并理清整个过程。
检验方法：
试着用自己的话说出对pod和service的理解 继续任务二 先备条件/知识:
搭建了两个节点以上的k8s集群 构建golang镜像推送到dockerhub中，详情见：https://k8s-tutorials.pages.dev/container.html pod # hellok8s.yaml apiVersion: v1 kind: Pod metadata: name: hellok8s labels: app: hellok8s spec: containers: - name: hellok8s-container image: rosylsq/hellok8s:v3 # 镜像请改成你自己的镜像 执行
kubectl apply -f hellok8s.yaml service # service.yaml apiVersion: v1 kind: Service metadata: name: service-hellok8s-nodeport spec: type: NodePort selector: app: hellok8s ports: - port: 3000 nodePort: 30000 targetPort: 3000 执行
kubectl apply -f service.]]></description>
</item>
<item>
    <title>操作系统——网络系统</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt_%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F/</link>
    <pubDate>Mon, 12 Jun 2023 11:34:52 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt_%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F/</guid>
    <description><![CDATA[优化文件传输的方式 分段总结 第一段总结:简单介绍什么是零拷贝
第二段总结:介绍DMA技术的作用
第三段总结:传统的文件传输存在上下文切换和数据拷贝次数多的问题
第四段总结:零拷贝技术通过降低上下文切换和数据拷贝次数优化文件传输性能
第五段总结: 具体分析mmap+write和sendfile两种方法如何实现零拷贝
第六段总结:介绍PageCache的作用以及对零拷贝的进一步优化
第七段总结: 针对大文件的传输应该使用异步IO+直接IO代替零拷贝
前六段总结:概括零拷贝技术 本段总结: 为大文件传输提供了更优方法 第八段总结:
前七段总结:讲解零拷贝技术和PageCache、直接IO等优化技术 本段总结: 总结零拷贝相关技术原理 问答 问题1:什么是零拷贝技术?作用是什么?
零拷贝技术是一种优化文件传输的方式,可以大幅减少传输过程中的CPU上下文切换次数和数据拷贝次数。具体来说: 降低上下文切换的次数:通过一次系统调用(如sendfile)可以完成读取磁盘和发送网络两个动作,减少了系统调用次数。 减少数据拷贝的次数:通过内核直接将磁盘数据拷贝到网络缓冲区,而非先拷贝到用户空间。 减少CPU参与数据搬运:通过DMA直接将磁盘数据搬运到网络缓冲区,不用CPU参与。 这些优化的作用是大幅提高文件传输的效率和吞吐量。 问题2:什么是DMA技术?作用是什么?
DMA(Direct Memory Access)直接内存访问技术。 作用是将I/O设备和内存之间的数据传输工作交给DMA控制器完成,而不是由CPU来完成。这样CPU就可以空闲出来执行其他任务,利用CPU的性能。 问题3:文件传输中的上下文切换具体是什么?
在文件传输过程中,需要从用户空间切换到内核态(系统调用),然后内核实现磁盘读取或网络发送操作,最后再从内核态切换回用户态。 这两个切换调用就称为一次上下文切换。传统文件传输方式需要多次系统调用,就需要多次上下文切换。 问题4:文件传输中为什么会发生数据拷贝?
传统文件传输方式会涉及多次的数据拷贝: 把磁盘数据拷贝到内核缓冲区 把内核缓冲区的数据拷贝到用户缓冲区 从用户缓冲区拷贝到网络缓冲区 把网络缓冲区的数据拷贝到网卡 问题5:mmap+write和sendfile如何实现零拷贝?
mmap + write: 通过mmap函数来映射内核缓冲区,省去拷贝到用户缓冲区这一步。 sendfile: 直接将内核缓冲区的数据拷贝到网络缓冲区,而非先拷贝到用户缓冲区。通过一次系统调用代替读写两个系统调用,减少上下文切换。 问题6:PageCahce的作用?
PageCache作为磁盘缓存,用来缓存最近访问的数据。它的作用主要有两个: 缓存最近被访问的数据,提高访问效率 通过预读及I/O合并,减少磁盘寻址和寻道时间,加快读取数据速度 问题7:如何对零拷贝进一步优化? 对零拷贝进一步优化的方法主要有: 使用scatter-gather DMA技术。 使用memcopy高效接口,如Intel的SOFTIRQ。 使用多核 CPU 提高DMA效率。 优化CPU和内存之间的TLB效率。 问题8:为什么针对大文件的传输应该使用异步IO+直接IO代替零拷贝?展开说明这一方案的具体过程。
对于大文件的传输: 难以充分利用PageCache,而PageCache又会被大量占用,影响小文件的读写。 大文件数据难以命中PageCache,多次DMA拷贝到PageCache会造成额外性能损耗。 因此,应该使用异步I/O + 直接I/O来传输大文件: 使用异步I/O,可以在磁盘读就位之前返回,用户进程可以执行其他任务,避免阻塞。 使用直接I/O,绕过PageCache,避免PageCache占用和额外的一次DMA拷贝。 直接I/O无法利用I/O合并和预读的优化,但对大文件来说影响不大。 总的来说,这种方式可以有效地传输大文件,而不会影响PageCache的性能。 own word DMA：是一种将文件数据从磁盘拷贝到内核缓冲区的技术，减轻CPU的负担 传统的文件传输方式 四次拷贝 调用read，然后由DMA从磁盘拷贝到内核缓冲区 由cpu从内核缓冲区拷贝到用户缓冲区 调用write，由cpu从用户缓冲区拷贝到网络缓冲区（socket） 由DMA从网络缓冲区拷贝到网卡 四次上下文切换 调用read，进程由用户态切换到内核态，完成后再切换到用户态 调用write，进程由用户态切换到内核态，完成后再切换到用户态 如何优化文件传输的性能？ 减少拷贝：从内核缓冲区拷贝到用户缓冲区，再从用户缓冲区拷贝到socket是没有必要的 减少上下文切换：每次系统调用就会有两次上下文切换，所以要减少系统调用 mmap + write mmap: 将内核缓冲区的数据映射到用户缓冲区，用户缓冲区并不是真正存储了这些数据，这样调用write的时候，就可以由CPU直接从内核缓冲区拷贝到socket中，减少了一次数据拷贝 sendfile 实现：传统的read+write分别定义了源文件和目的文件描述符，sendfile直接定义了两者，这样就可以直接从内核缓冲区拷贝到socket中，减少了一次数据拷贝的同时，减少了一次系统调通，即减少了两次上下文切换 如果网卡支持（零拷贝） 可以从内核缓冲区直接拷贝到网卡，减少一次数据拷贝 零拷贝的思想就是，将文件的拷贝完全交给DMA，全程不用CPU参与 I/O 多路复用：select/poll/epoll 分段总结 第一段总结: 最基本的 Socket 模型,描述了通过 Socket 实现 TCP 网络连接的基本过程。]]></description>
</item>
<item>
    <title>操作系统——文件系统</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</link>
    <pubDate>Mon, 12 Jun 2023 11:32:12 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</guid>
    <description><![CDATA[进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？ 分段总结 第一段总结:进程写文件时发生了崩溃,已写入的数据不会丢失,因为数据已写入内核的page cache中。
第二段总结: 页面缓存page cache是 linux文件系统的内存缓存,用于加速读写。
第三段总结:
前两段总结: 内核的page cache机制用于加速文件读写。 本段总结:文章介绍了page cache的工作原理。 第四段总结:
前三段总结: 通过page cache内存缓存加速文件读写。 本段总结:通过example说明了如何查看系统的page cache。 第五段总结:
前四段总结:通过例子了解page cache。 本段总结: 介绍了page、 page cache和被换出的page。 问答 问题1:什么是page cache?page cache的工作原理是什么?
答案:Page cache是内核管理的内存区域,用于缓存磁盘上的文件数据。程序通过read系统调用或者mmap将文件数据读取到page cache中。Page cache的工作原理是,文件I/O首先写入page cache,然后page cache再同步到磁盘。 问题2:举例说明page cache的工作原理?
答案:例如进程读取了一个文件的前4KB数据,由于磁盘的最小I/O单位为4KB,内核实际会将0-4KB的数据加载到page cache中。内核可能会再将4-8KB、8-12KB的数据进行预读,缓存在page cache中。 问题3:page,page cache和被换出的page有什么区别?
答案: page 是内存分配的基本单位,page cache由多个page构成。 page cache中的page对应磁盘上的文件数据,被称为文件归类(file-backed)页。 被换出的page则对应交换分区中的数据,称为匿名页(anonymous page)。 问题4:buffer cache 是什么?和page cache 有什么区别和关系?
答案:Buffer cache用于缓存块设备(如磁盘)的数据块,page cache用于缓存文件的数据页。 如果一个文件的数据页装入了page cache,对应的磁盘块数据会指向这个页,buffer cache只需维护指针即可。 现在我们通常将buffer cache 和page cache统称为page cache。 问题5:预读是什么?和page cache 有什么关系?]]></description>
</item>
<item>
    <title>操作系统——进程管理</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt_%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
    <pubDate>Mon, 12 Jun 2023 11:15:22 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt_%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
    <description><![CDATA[多线程冲突了怎么办？ 分段总结 第一段总结: 提供了互斥锁和信号量两个同步方法。
第二段总结: 讲述了不同类型的锁,互斥的概念和同步的概念。
第三段总结:
前两段总结: 提供了互斥锁和信号量两个同步方法。 本段总结: 详细介绍了信号量的概念和PV操作。 第四段总结:
前三段总结: 提供了互斥锁和信号量两个同步方法。详细介绍了信号量的概念和PV操作。 本段总结: 使用信号量实现了生产者消费者问题。 第五段总结:
前四段总结:提供了互斥锁和信号量两个同步方法。使用信号量实现了生产者消费者问题。 本段总结: 分析了哲学家就餐问题,提出了几种解决方案。 第六段总结:
前五段总结:提供了互斥锁和信号量两个同步方法。使用信号量实现了生产者消费者问题。分析了哲学家就餐问题, 提出了几种解决方案。 本段总结: 分析了读者写者问题,提出了几种解决方案。 问答 1、什么是互斥?
互斥指在访问共享资源时,只允许一个进程或者线程访问,其他进程或者线程需要被阻止。 2、什么是同步?
同步指在并发执行的进程或者线程之间需要在某些关键点相互等待和通信,以协调他们的动作。 3、信号量如何实现同步?
使用信号量中的 P 和 V 操作实现同步。 P 操作将信号量减1,如果信号量小于0则阻塞;V 操作将信号量加1,并唤醒一个阻塞的线程。 当需要同步时,在关键点上执行相应的 P 和 V 操作。 4、什么是生产者消费者问题?这是同步问题还是互斥问题?如何解决?
生产者生产产品,消费者消费产品。缓冲区既是生产者和消费者共享的资源,所以这是同步和互斥问题。 解决方法是: 互斥信号量 mutex 互斥访问缓冲区 资源信号量 fullBuffers 和 emptyBuffers 来同步生产者和消费者 生产者获取 emptyBuffers,消费者获取 fullBuffers 来实现同步。 5、什么是哲学家就餐问题?如何解决?
多个哲学家周围有几个叉子,每个哲学家要同时拿起左右两个叉子才能进餐。 解决方法是: 使用信号量fork[N]来表示每个叉子 每个哲学家执行 P(fork[i]) 和 P(fork[(i+1)%N]) 来试图获得左右两个叉子 解决问题的关键在于设计合理的获取叉子的顺序,以避免死锁 6、什么是读者写者问题?如何解决?]]></description>
</item>
<item>
    <title>操作系统——内存管理</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
    <pubDate>Sat, 10 Jun 2023 14:31:42 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
    <description><![CDATA[为什么要有虚拟内存 流程图 总结 第一段总结:介绍了虚拟内存的主要作用和内存分段。
第二段总结:解释了内存分段为什么容易产生内存碎片以及内存交换效率低的原因。
第三段总结:
前两段总结:介绍了虚拟内存和内存分段。 本段总结: 介绍了内存分页如何解决分段产生的内存碎片和低效率问题。 第四段总结:
前三段总结:介绍了虚拟内存、内存分段和内存分页。 本段总结:解释了简单分页机制产生的页表占用空间问题。 第五段总结:
前四段总结:介绍了虚拟内存、内存分段、内存分页和简单分页机制。 本段总结:介绍多级分页来解决页表占用空间问题。 第六段总结:
前五段总结:解释了虚拟内存、内存分段、分页、多级页表。 本段总结:介绍了 TLB 来提高地址转换效率。 第七段总结:
前六段总结:讲解了多级分页页表和 TLB。 本段总结: 说明了Linux主要采用分页管理虽然也涉及到分段管理。 第八段总结:
前七段总结:介绍了Linux主要采用分页管理。 本段总结:说明了Linux虚拟地址空间的布局。 第九段总结:
前八段总结:解释了 Linux 内存管理方式及其虚拟地址空间布局。 本段总结:总结介绍了虚拟内存的主要作用。 问答 问题1:虚拟内存的主要作用是什么?
主要有两点作用: 可以使程序运行的内存大小超过实际物理内存。通过内存换出和换入,不常用的内存页写到硬盘,需要时再读回。 为每个进程提供独立的虚拟地址空间,解决了不同进程地址冲突的问题。每个进程看到的都是同样的虚拟地址,实际物理地址 通过页表映射而不同。 问题2:介绍一下内存分段?
内存分段是按照程序逻辑把内存划分为代码段、数据段、栈段等段。每个段有不同的属性。 虚拟地址是由段选择符和段内偏移量组成。段选择符索引到段表获取段的基地址,然后结合段内偏移量计算出物理地址。 分段能产生连续地址空间,但会产生外部内存碎片,影响内存交换效率。 问题3:介绍一下内存分页?
内存分页是将虚拟地址空间和物理内存均划分为大小固定(如4KB)的页。 虚拟地址由页号和页内偏移组成。页号索引到页表得到物理页地址,与页内偏移相加得到物理地址。 分页减少了内存碎片,并提高了内存交换效率。 问题4:介绍一下多级页表?
为解决简单分页导致的页表太大问题,采用多级页表。 比如将一级页表分成多个二级页表,二级页表上的页表项数减少。仅在需要时创建下级页表。 这样使用时分布在各级页表上的页表项数显著减少,节省了大量内存。 问题5:介绍一下TLB?
TLB即转换查询缓存。位于CPU和MMU之间。 可以缓存最近访问过的虚拟地址和物理地址的映射。 为解决多级页表导致的地址转换时间长的问题。 TLB的命中率高,能大大提高地址转换效率。 问题6:介绍一下Linux的内存管理方式?
Linux主要采用的是分页式内存管理。 但是由于x86处理器支持分段式和分页式内存管理,Linux不得不采用段式内存管理。 但是Linux会把所有的段基地址设为0,相当于屏蔽了分段,段只用于访问控制和保护。 问题7:介绍一下Linux虚拟地址空间的布局?
Linux虚拟地址空间分为:内核空间和用户空间。 用户空间分为:代码段、数据段、BSS段、堆区、文件映射区、栈区。 malloc是如何分配内存的？ 流程图 总结 一段文本的总结如下:
第一段总结: malloc 分配内存的两种方式及大小阈值。]]></description>
</item>
<item>
    <title>解决LoveIt代码块超出屏幕范围的问题</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E4%B8%BAhugo%E6%B7%BB%E5%8A%A0%E6%A0%B7%E5%BC%8F/</link>
    <pubDate>Fri, 09 Jun 2023 20:09:54 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E4%B8%BAhugo%E6%B7%BB%E5%8A%A0%E6%A0%B7%E5%BC%8F/</guid>
    <description><![CDATA[在themes\Lovelt\assets\css\style.scss底部添加下列代码
pre { overflow-x: auto; white-space: pre-wrap; word-wrap: break-word; max-width: 100%; } ]]></description>
</item>
<item>
    <title>基于hugo&#43;github page搭建博客</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E5%9F%BA%E4%BA%8Ehugo&#43;github-page%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</link>
    <pubDate>Thu, 08 Jun 2023 22:57:51 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E5%9F%BA%E4%BA%8Ehugo&#43;github-page%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</guid>
    <description><![CDATA[本地运行 1. 安装 Hugo 首先，从 Hugo 官网 下载并安装适用于您操作系统的 Hugo。
2. 创建新的 Hugo 站点 打开命令行工具，然后输入以下命令创建一个新的 Hugo 站点：
hugo new site my-blog 这将在当前目录下创建一个名为 &ldquo;my-blog&rdquo; 的文件夹，其中包含 Hugo 站点的所有文件和目录。
3. 选择一个主题 浏览 Hugo 主题库，选择一个合适的主题。这里以本博客的主题为例： &ldquo;Loveit&rdquo; ，将其添加到你的站点中：
cd my-blog git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt 将主题添加到站点配置文件 config.toml 中：
theme = &#34;example-theme&#34; 4. 创建内容 使用以下命令创建一篇新的博客文章：
hugo new posts/my-first-post.md 这将在 content/posts 目录下创建一个名为 &ldquo;my-first-post.md&rdquo; 的 Markdown 文件。编辑该文件，添加您的博客内容。
5. 预览博客 在本地预览您的博客，输入以下命令：
hugo server 这将启动一个本地服务器，访问 http://localhost:1313 可以预览您的博客。
部署到 GitHub Pages 1.]]></description>
</item>
<item>
    <title>阅读prompt</title>
    <link>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/</link>
    <pubDate>Thu, 08 Jun 2023 22:57:51 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/</guid>
    <description><![CDATA[first prompt（总结） 你是善于总结和提取关键信息的助手。
我会给你一段文本，请你按照下列要求总结文本，最后再给出阅读建议：
总结第一段 总结第二段 总结前面两段，并总结第三段 总结前面三段，并总结第四段 &hellip;&hellip; 总结前面n-1段，并总结第n段，直到总结完全文。 所有的总结都在一句话之内完成。 回答的格式为：
第一段总结：
第二段总结：
第三段总结：
前两段总结： 本段总结： 第四段总结：
前三段总结： 本段总结 &hellip;&hellip;
第n段总结
前n-1段总结： 本段总结： 文本：
结果 总结如下:
第一段总结:介绍了虚拟内存的主要作用和内存分段。
第二段总结:解释了内存分段为什么容易产生内存碎片以及内存交换效率低的原因。
第三段总结:
前两段总结:介绍了虚拟内存和内存分段。 本段总结: 介绍了内存分页如何解决分段产生的内存碎片和低效率问题。 第四段总结:
前三段总结:介绍了虚拟内存、内存分段和内存分页。 本段总结:解释了简单分页机制产生的页表占用空间问题。 第五段总结:
前四段总结:介绍了虚拟内存、内存分段、内存分页和简单分页机制。 本段总结:介绍多级分页来解决页表占用空间问题。 第六段总结:
前五段总结:解释了虚拟内存、内存分段、分页、多级页表。 本段总结:介绍了 TLB 来提高地址转换效率。 第七段总结:
前六段总结:讲解了多级分页页表和 TLB。 本段总结: 说明了Linux主要采用分页管理虽然也涉及到分段管理。 第八段总结:
前七段总结:介绍了Linux主要采用分页管理。 本段总结:说明了Linux虚拟地址空间的布局。 第九段总结:
前八段总结:解释了 Linux 内存管理方式及其虚拟地址空间布局。 本段总结:总结介绍了虚拟内存的主要作用。 second prompt 2（回答问题） 你是计算机行业的求职者，你的任务是回答面试官给你的问题，得到面试官的青睐
你的问题必须基于我的文本来回答。
问题1：虚拟内存的主要作用是什么？
问题2：介绍一下内存分段？
问题3：介绍一下内存分页？
问题4：介绍一下多级页表？
问题5：介绍一下TLB？
问题6：介绍一下Linux的内存管理方式？
问题7：介绍一下Linux虚拟地址空间的布局？
文本：]]></description>
</item>
</channel>
</rss>
