<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>阅读prompt - My New Hugo Site</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="阅读prompt" />
<meta property="og:description" content="first prompt（总结） 你是善于总结和提取关键信息的助手。
我会给你一段文本，请你按照下列要求总结文本，最后再给出阅读建议：
总结第一段 总结第二段 总结前面两段，并总结第三段 总结前面三段，并总结第四段 &hellip;&hellip; 总结前面n-1段，并总结第n段，直到总结完全文。 所有的总结都在一句话之内完成。 回答的格式为：
第一段总结：
第二段总结：
第三段总结：
前两段总结： 本段总结： 第四段总结：
前三段总结： 本段总结 &hellip;&hellip;
第n段总结
前n-1段总结： 本段总结： 文本：
4.1 为什么要有虚拟内存？ 本篇跟大家说说内存管理，内存管理还是比较重要的一个环节，理解了它，至少对整个操作系统的工作会有一个初步的轮廓，这也难怪面试的时候常问内存管理。 干就完事，本文的提纲： #虚拟内存 如果你是电子相关专业的，肯定在大学里捣鼓过单片机。 单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。 另外，单片机的 CPU 是直接操作内存的「物理地址」。 在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。 操作系统是如何解决这个问题呢？ 这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。 我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。 进程的中间层 操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。 如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。 于是，这里就引出了两种地址的概念： 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。 操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示： 操作系统是如何管理虚拟地址与物理地址之间的关系？ 主要有两种方式，分别是内存分段和内存分页，分段是比较早提出的，我们先来看看内存分段。 #内存分段 程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。 分段机制下，虚拟地址和物理地址是如何映射的？ 分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。 段选择因子和段内偏移量： 段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。 在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图： 如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 &#43; 偏移量 500 = 7500。 分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处： 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。 接下来，说说为什么会有这两个问题。 我们先来看看，分段为什么会产生内存碎片的问题？ 我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中： 游戏占用了 512MB 内存 浏览器占用了 128MB 内存 音乐占用了 256 MB 内存。 这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。 如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。 内存分段会出现内存碎片吗？ 内存碎片主要分为，内部内存碎片和外部内存碎片。 内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。 但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。 解决「外部内存碎片」的问题就是内存交换。 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。 这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。 再来看看，分段为什么会导致内存交换效率低的问题？ 对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。 因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。 所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。 为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。 #内存分页 分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。 要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。 分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。 虚拟地址与物理地址之间通过页表来映射，如下图： 页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。 而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？ 内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。 但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。 如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。 更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。 分页机制下，虚拟地址和物理地址是如何映射的？ 在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。 总结一下，对于一个内存地址转换，其实就是这样三个步骤： 把虚拟内存地址，切分成页号和偏移量； 根据页号，从页表里面，查询对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。 下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图： 这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定是会有问题的。 简单的分页有什么缺陷吗？ 有空间上的缺陷。 因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。 在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。 这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。 那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。 #多级页表 要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。 在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。 我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示： 你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）&#43; 4MB（二级页表）的内存，这样占用空间不是更大了吗？ 当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。 其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？ 每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） &#43; 20% * 4MB（二级页表）= 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-08T22:57:51+08:00" />
<meta property="article:modified_time" content="2023-06-08T22:57:51+08:00" /><meta property="og:site_name" content="My cool site" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="阅读prompt"/>
<meta name="twitter:description" content="first prompt（总结） 你是善于总结和提取关键信息的助手。
我会给你一段文本，请你按照下列要求总结文本，最后再给出阅读建议：
总结第一段 总结第二段 总结前面两段，并总结第三段 总结前面三段，并总结第四段 &hellip;&hellip; 总结前面n-1段，并总结第n段，直到总结完全文。 所有的总结都在一句话之内完成。 回答的格式为：
第一段总结：
第二段总结：
第三段总结：
前两段总结： 本段总结： 第四段总结：
前三段总结： 本段总结 &hellip;&hellip;
第n段总结
前n-1段总结： 本段总结： 文本：
4.1 为什么要有虚拟内存？ 本篇跟大家说说内存管理，内存管理还是比较重要的一个环节，理解了它，至少对整个操作系统的工作会有一个初步的轮廓，这也难怪面试的时候常问内存管理。 干就完事，本文的提纲： #虚拟内存 如果你是电子相关专业的，肯定在大学里捣鼓过单片机。 单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。 另外，单片机的 CPU 是直接操作内存的「物理地址」。 在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。 操作系统是如何解决这个问题呢？ 这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。 我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。 进程的中间层 操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。 如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。 于是，这里就引出了两种地址的概念： 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。 操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示： 操作系统是如何管理虚拟地址与物理地址之间的关系？ 主要有两种方式，分别是内存分段和内存分页，分段是比较早提出的，我们先来看看内存分段。 #内存分段 程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。 分段机制下，虚拟地址和物理地址是如何映射的？ 分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。 段选择因子和段内偏移量： 段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。 在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图： 如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 &#43; 偏移量 500 = 7500。 分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处： 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。 接下来，说说为什么会有这两个问题。 我们先来看看，分段为什么会产生内存碎片的问题？ 我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中： 游戏占用了 512MB 内存 浏览器占用了 128MB 内存 音乐占用了 256 MB 内存。 这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。 如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。 内存分段会出现内存碎片吗？ 内存碎片主要分为，内部内存碎片和外部内存碎片。 内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。 但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。 解决「外部内存碎片」的问题就是内存交换。 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。 这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。 再来看看，分段为什么会导致内存交换效率低的问题？ 对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。 因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。 所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。 为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。 #内存分页 分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。 要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。 分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。 虚拟地址与物理地址之间通过页表来映射，如下图： 页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。 而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？ 内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。 但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。 如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。 更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。 分页机制下，虚拟地址和物理地址是如何映射的？ 在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。 总结一下，对于一个内存地址转换，其实就是这样三个步骤： 把虚拟内存地址，切分成页号和偏移量； 根据页号，从页表里面，查询对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。 下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图： 这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定是会有问题的。 简单的分页有什么缺陷吗？ 有空间上的缺陷。 因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。 在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。 这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。 那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。 #多级页表 要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。 在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。 我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示： 你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）&#43; 4MB（二级页表）的内存，这样占用空间不是更大了吗？ 当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。 其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？ 每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） &#43; 20% * 4MB（二级页表）= 0."/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/" /><link rel="next" href="https://rosouly.github.io/rosy.github.io/posts/my-first-post/" /><link rel="stylesheet" href="/rosy.github.io/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "阅读prompt",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/rosouly.github.io\/rosy.github.io\/posts\/%E9%98%85%E8%AF%BBprompt\/"
        },"genre": "posts","wordcount":  962 ,
        "url": "https:\/\/rosouly.github.io\/rosy.github.io\/posts\/%E9%98%85%E8%AF%BBprompt\/","datePublished": "2023-06-08T22:57:51+08:00","dateModified": "2023-06-08T22:57:51+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Author"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/rosy.github.io/" title="My New Hugo Site">My cool site</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/rosy.github.io/posts/"> Post </a><a class="menu-item" href="/rosy.github.io/about/"> About </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/rosy.github.io/" title="My New Hugo Site">My cool site</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/rosy.github.io/posts/" title="">Post</a><a class="menu-item" href="/rosy.github.io/about/" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">阅读prompt</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/rosy.github.io/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Author</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2023-06-08">2023-06-08</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;962 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#first">first</a>
      <ul>
        <li><a href="#prompt总结">prompt（总结）</a></li>
        <li><a href="#结果">结果</a></li>
      </ul>
    </li>
    <li><a href="#second">second</a>
      <ul>
        <li><a href="#prompt-2回答问题">prompt 2（回答问题）</a></li>
        <li><a href="#答案">答案</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="first">first</h2>
<h3 id="prompt总结">prompt（总结）</h3>
<p>你是善于总结和提取关键信息的助手。</p>
<p>我会给你一段文本，请你按照下列要求总结文本，最后再给出阅读建议：</p>
<ul>
<li>总结第一段</li>
<li>总结第二段</li>
<li>总结前面两段，并总结第三段</li>
<li>总结前面三段，并总结第四段
&hellip;&hellip;</li>
<li>总结前面n-1段，并总结第n段，直到总结完全文。</li>
<li>所有的总结都在一句话之内完成。</li>
</ul>
<p>回答的格式为：</p>
<p>第一段总结：</p>
<p>第二段总结：</p>
<p>第三段总结：</p>
<ul>
<li>前两段总结：</li>
<li>本段总结：</li>
</ul>
<p>第四段总结：</p>
<ul>
<li>前三段总结：</li>
<li>本段总结</li>
</ul>
<p>&hellip;&hellip;</p>
<p>第n段总结</p>
<ul>
<li>前n-1段总结：</li>
<li>本段总结：</li>
</ul>
<p>文本：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>4.1 为什么要有虚拟内存？
</span></span><span style="display:flex;"><span>本篇跟大家说说内存管理，内存管理还是比较重要的一个环节，理解了它，至少对整个操作系统的工作会有一个初步的轮廓，这也难怪面试的时候常问内存管理。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>干就完事，本文的提纲：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#虚拟内存
</span></span><span style="display:flex;"><span>如果你是电子相关专业的，肯定在大学里捣鼓过单片机。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>另外，单片机的 CPU 是直接操作内存的「物理地址」。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>操作系统是如何解决这个问题呢？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>进程的中间层
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>于是，这里就引出了两种地址的概念：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）
</span></span><span style="display:flex;"><span>实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。
</span></span><span style="display:flex;"><span>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>操作系统是如何管理虚拟地址与物理地址之间的关系？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>主要有两种方式，分别是内存分段和内存分页，分段是比较早提出的，我们先来看看内存分段。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#内存分段
</span></span><span style="display:flex;"><span>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分段机制下，虚拟地址和物理地址是如何映射的？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段选择因子和段内偏移量：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>第一个就是内存碎片的问题。
</span></span><span style="display:flex;"><span>第二个就是内存交换的效率低的问题。
</span></span><span style="display:flex;"><span>接下来，说说为什么会有这两个问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们先来看看，分段为什么会产生内存碎片的问题？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>游戏占用了 512MB 内存
</span></span><span style="display:flex;"><span>浏览器占用了 128MB 内存
</span></span><span style="display:flex;"><span>音乐占用了 256 MB 内存。
</span></span><span style="display:flex;"><span>这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分段会出现内存碎片吗？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存碎片主要分为，内部内存碎片和外部内存碎片。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>解决「外部内存碎片」的问题就是内存交换。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>再来看看，分段为什么会导致内存交换效率低的问题？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#内存分页
</span></span><span style="display:flex;"><span>分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>虚拟地址与物理地址之间通过页表来映射，如下图：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分页机制下，虚拟地址和物理地址是如何映射的？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>总结一下，对于一个内存地址转换，其实就是这样三个步骤：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>把虚拟内存地址，切分成页号和偏移量；
</span></span><span style="display:flex;"><span>根据页号，从页表里面，查询对应的物理页号；
</span></span><span style="display:flex;"><span>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。
</span></span><span style="display:flex;"><span>下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定是会有问题的。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>简单的分页有什么缺陷吗？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>有空间上的缺陷。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#多级页表
</span></span><span style="display:flex;"><span>要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那么为什么不分级的页表就做不到这样节约内存呢？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>全局页目录项 PGD（Page Global Directory）；
</span></span><span style="display:flex;"><span>上层页目录项 PUD（Page Upper Directory）；
</span></span><span style="display:flex;"><span>中间页目录项 PMD（Page Middle Directory）；
</span></span><span style="display:flex;"><span>页表项 PTE（Page Table Entry）；
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#TLB
</span></span><span style="display:flex;"><span>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#段页式内存管理
</span></span><span style="display:flex;"><span>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段页式内存管理实现的方式：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
</span></span><span style="display:flex;"><span>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
</span></span><span style="display:flex;"><span>这样，地址结构就由段号、段内页号和页内位移三部分组成。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段页式地址变换中要得到物理地址须经过三次内存访问：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>第一次访问段表，得到页表起始地址；
</span></span><span style="display:flex;"><span>第二次访问页表，得到物理页号；
</span></span><span style="display:flex;"><span>第三次将物理页号与页内位移组合，得到物理地址。
</span></span><span style="display:flex;"><span>可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#Linux 内存布局
</span></span><span style="display:flex;"><span>那么，Linux 操作系统采用了哪种方式来管理内存呢？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在回答这个问题前，我们得先看看 Intel 处理器的发展历史。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>早期 Intel 的处理器从 80286 开始使用的是段式内存管理。但是很快发现，光有段式内存管理而没有页式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争力。因此，在不久以后的 80386 中就实现了页式内存管理。也就是说，80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了页式内存管理。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是这个 80386 的页式内存管理设计时，没有绕开段式内存管理，而是建立在段式内存管理的基础上，这就意味着，页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>由于此时由段式内存管理映射而成的地址不再是“物理地址”了，Intel 就称之为“线性地址”（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这里说明下逻辑地址和线性地址：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>程序所使用的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；
</span></span><span style="display:flex;"><span>通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址；
</span></span><span style="display:flex;"><span>逻辑地址是「段式内存管理」转换前的地址，线性地址则是「页式内存管理」转换前的地址。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>了解完 Intel 处理器的发展历史后，我们再来说说 Linux 采用了什么方式管理内存？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这主要是上面 Intel 处理器发展历史导致的，因为 Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。既然 CPU 的硬件结构是这样，Linux 内核也只好服从 Intel 的选择。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是事实上，Linux 内核所采取的办法是使段式映射的过程实际上不起什么作用。也就是说，“上有政策，下有对策”，若惹不起就躲着走。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们再来瞧一瞧，Linux 的虚拟地址空间是如何分布的？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>通过这里可以看出：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；
</span></span><span style="display:flex;"><span>64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
</span></span><span style="display:flex;"><span>再来说说，内核空间与用户空间的区别：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>进程在用户态时，只能访问用户空间内存；
</span></span><span style="display:flex;"><span>只有进入内核态后，才可以访问内核空间的内存；
</span></span><span style="display:flex;"><span>虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>虚拟内存空间划分
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>通过这张图你可以看到，用户空间内存，从低到高分别是 6 种不同的内存段：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>代码段，包括二进制可执行代码；
</span></span><span style="display:flex;"><span>数据段，包括已初始化的静态常量和全局变量；
</span></span><span style="display:flex;"><span>BSS 段，包括未初始化的静态变量和全局变量；
</span></span><span style="display:flex;"><span>堆段，包括动态分配的内存，从低地址开始向上增长；
</span></span><span style="display:flex;"><span>文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）；
</span></span><span style="display:flex;"><span>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；
</span></span><span style="display:flex;"><span>上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#总结
</span></span><span style="display:flex;"><span>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>再来，为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>另外，Linux 系统中虚拟空间分布可分为用户态和内核态两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>最后，说下虚拟内存有什么作用？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
</span></span><span style="display:flex;"><span>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
</span></span><span style="display:flex;"><span>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
</span></span></code></pre></div><h3 id="结果">结果</h3>
<p>总结如下:</p>
<p>第一段总结:介绍了虚拟内存的主要作用和内存分段。</p>
<p>第二段总结:解释了内存分段为什么容易产生内存碎片以及内存交换效率低的原因。</p>
<p>第三段总结:</p>
<ul>
<li>前两段总结:介绍了虚拟内存和内存分段。</li>
<li>本段总结: 介绍了内存分页如何解决分段产生的内存碎片和低效率问题。</li>
</ul>
<p>第四段总结:</p>
<ul>
<li>前三段总结:介绍了虚拟内存、内存分段和内存分页。</li>
<li>本段总结:解释了简单分页机制产生的页表占用空间问题。</li>
</ul>
<p>第五段总结:</p>
<ul>
<li>前四段总结:介绍了虚拟内存、内存分段、内存分页和简单分页机制。</li>
<li>本段总结:介绍多级分页来解决页表占用空间问题。</li>
</ul>
<p>第六段总结:</p>
<ul>
<li>前五段总结:解释了虚拟内存、内存分段、分页、多级页表。</li>
<li>本段总结:介绍了 TLB 来提高地址转换效率。</li>
</ul>
<p>第七段总结:</p>
<ul>
<li>前六段总结:讲解了多级分页页表和 TLB。</li>
<li>本段总结: 说明了Linux主要采用分页管理虽然也涉及到分段管理。</li>
</ul>
<p>第八段总结:</p>
<ul>
<li>前七段总结:介绍了Linux主要采用分页管理。</li>
<li>本段总结:说明了Linux虚拟地址空间的布局。</li>
</ul>
<p>第九段总结:</p>
<ul>
<li>前八段总结:解释了 Linux 内存管理方式及其虚拟地址空间布局。</li>
<li>本段总结:总结介绍了虚拟内存的主要作用。</li>
</ul>
<h2 id="second">second</h2>
<h3 id="prompt-2回答问题">prompt 2（回答问题）</h3>
<p>你是计算机行业的求职者，你的任务是回答面试官给你的问题，得到面试官的青睐</p>
<p>你的问题必须基于我的文本来回答。</p>
<p>问题1：虚拟内存的主要作用是什么？</p>
<p>问题2：介绍一下内存分段？</p>
<p>问题3：介绍一下内存分页？</p>
<p>问题4：介绍一下多级页表？</p>
<p>问题5：介绍一下TLB？</p>
<p>问题6：介绍一下Linux的内存管理方式？</p>
<p>问题7：介绍一下Linux虚拟地址空间的布局？</p>
<p>文本：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>4.1 为什么要有虚拟内存？
</span></span><span style="display:flex;"><span>本篇跟大家说说内存管理，内存管理还是比较重要的一个环节，理解了它，至少对整个操作系统的工作会有一个初步的轮廓，这也难怪面试的时候常问内存管理。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>干就完事，本文的提纲：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#虚拟内存
</span></span><span style="display:flex;"><span>如果你是电子相关专业的，肯定在大学里捣鼓过单片机。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>另外，单片机的 CPU 是直接操作内存的「物理地址」。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>操作系统是如何解决这个问题呢？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>进程的中间层
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>于是，这里就引出了两种地址的概念：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）
</span></span><span style="display:flex;"><span>实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。
</span></span><span style="display:flex;"><span>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>操作系统是如何管理虚拟地址与物理地址之间的关系？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>主要有两种方式，分别是内存分段和内存分页，分段是比较早提出的，我们先来看看内存分段。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#内存分段
</span></span><span style="display:flex;"><span>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分段机制下，虚拟地址和物理地址是如何映射的？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段选择因子和段内偏移量：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>第一个就是内存碎片的问题。
</span></span><span style="display:flex;"><span>第二个就是内存交换的效率低的问题。
</span></span><span style="display:flex;"><span>接下来，说说为什么会有这两个问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们先来看看，分段为什么会产生内存碎片的问题？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>游戏占用了 512MB 内存
</span></span><span style="display:flex;"><span>浏览器占用了 128MB 内存
</span></span><span style="display:flex;"><span>音乐占用了 256 MB 内存。
</span></span><span style="display:flex;"><span>这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分段会出现内存碎片吗？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存碎片主要分为，内部内存碎片和外部内存碎片。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>解决「外部内存碎片」的问题就是内存交换。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>再来看看，分段为什么会导致内存交换效率低的问题？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#内存分页
</span></span><span style="display:flex;"><span>分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>虚拟地址与物理地址之间通过页表来映射，如下图：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>分页机制下，虚拟地址和物理地址是如何映射的？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>总结一下，对于一个内存地址转换，其实就是这样三个步骤：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>把虚拟内存地址，切分成页号和偏移量；
</span></span><span style="display:flex;"><span>根据页号，从页表里面，查询对应的物理页号；
</span></span><span style="display:flex;"><span>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。
</span></span><span style="display:flex;"><span>下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定是会有问题的。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>简单的分页有什么缺陷吗？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>有空间上的缺陷。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#多级页表
</span></span><span style="display:flex;"><span>要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那么为什么不分级的页表就做不到这样节约内存呢？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>全局页目录项 PGD（Page Global Directory）；
</span></span><span style="display:flex;"><span>上层页目录项 PUD（Page Upper Directory）；
</span></span><span style="display:flex;"><span>中间页目录项 PMD（Page Middle Directory）；
</span></span><span style="display:flex;"><span>页表项 PTE（Page Table Entry）；
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#TLB
</span></span><span style="display:flex;"><span>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#段页式内存管理
</span></span><span style="display:flex;"><span>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段页式内存管理实现的方式：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
</span></span><span style="display:flex;"><span>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
</span></span><span style="display:flex;"><span>这样，地址结构就由段号、段内页号和页内位移三部分组成。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>段页式地址变换中要得到物理地址须经过三次内存访问：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>第一次访问段表，得到页表起始地址；
</span></span><span style="display:flex;"><span>第二次访问页表，得到物理页号；
</span></span><span style="display:flex;"><span>第三次将物理页号与页内位移组合，得到物理地址。
</span></span><span style="display:flex;"><span>可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#Linux 内存布局
</span></span><span style="display:flex;"><span>那么，Linux 操作系统采用了哪种方式来管理内存呢？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在回答这个问题前，我们得先看看 Intel 处理器的发展历史。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>早期 Intel 的处理器从 80286 开始使用的是段式内存管理。但是很快发现，光有段式内存管理而没有页式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争力。因此，在不久以后的 80386 中就实现了页式内存管理。也就是说，80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了页式内存管理。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是这个 80386 的页式内存管理设计时，没有绕开段式内存管理，而是建立在段式内存管理的基础上，这就意味着，页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>由于此时由段式内存管理映射而成的地址不再是“物理地址”了，Intel 就称之为“线性地址”（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这里说明下逻辑地址和线性地址：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>程序所使用的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；
</span></span><span style="display:flex;"><span>通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址；
</span></span><span style="display:flex;"><span>逻辑地址是「段式内存管理」转换前的地址，线性地址则是「页式内存管理」转换前的地址。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>了解完 Intel 处理器的发展历史后，我们再来说说 Linux 采用了什么方式管理内存？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这主要是上面 Intel 处理器发展历史导致的，因为 Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。既然 CPU 的硬件结构是这样，Linux 内核也只好服从 Intel 的选择。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但是事实上，Linux 内核所采取的办法是使段式映射的过程实际上不起什么作用。也就是说，“上有政策，下有对策”，若惹不起就躲着走。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们再来瞧一瞧，Linux 的虚拟地址空间是如何分布的？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>通过这里可以看出：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；
</span></span><span style="display:flex;"><span>64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
</span></span><span style="display:flex;"><span>再来说说，内核空间与用户空间的区别：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>进程在用户态时，只能访问用户空间内存；
</span></span><span style="display:flex;"><span>只有进入内核态后，才可以访问内核空间的内存；
</span></span><span style="display:flex;"><span>虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>虚拟内存空间划分
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>通过这张图你可以看到，用户空间内存，从低到高分别是 6 种不同的内存段：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>代码段，包括二进制可执行代码；
</span></span><span style="display:flex;"><span>数据段，包括已初始化的静态常量和全局变量；
</span></span><span style="display:flex;"><span>BSS 段，包括未初始化的静态变量和全局变量；
</span></span><span style="display:flex;"><span>堆段，包括动态分配的内存，从低地址开始向上增长；
</span></span><span style="display:flex;"><span>文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）；
</span></span><span style="display:flex;"><span>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；
</span></span><span style="display:flex;"><span>上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#总结
</span></span><span style="display:flex;"><span>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>再来，为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>另外，Linux 系统中虚拟空间分布可分为用户态和内核态两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>最后，说下虚拟内存有什么作用？
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
</span></span><span style="display:flex;"><span>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
</span></span><span style="display:flex;"><span>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
</span></span></code></pre></div><h3 id="答案">答案</h3>
<p>问题1:虚拟内存的主要作用是什么?</p>
<p>主要有两点作用:</p>
<p>可以使程序运行的内存大小超过实际物理内存。通过内存换出和换入,不常用的内存页写到硬盘,需要时再读回。</p>
<p>为每个进程提供独立的虚拟地址空间,解决了不同进程地址冲突的问题。每个进程看到的都是同样的虚拟地址,实际物理地址 通过页表映射而不同。</p>
<p>问题2:介绍一下内存分段?</p>
<p>内存分段是按照程序逻辑把内存划分为代码段、数据段、栈段等段。每个段有不同的属性。
虚拟地址是由段选择符和段内偏移量组成。段选择符索引到段表获取段的基地址,然后结合段内偏移量计算出物理地址。
分段能产生连续地址空间,但会产生外部内存碎片,影响内存交换效率。</p>
<p>问题3:介绍一下内存分页?</p>
<p>内存分页是将虚拟地址空间和物理内存均划分为大小固定(如4KB)的页。
虚拟地址由页号和页内偏移组成。页号索引到页表得到物理页地址,与页内偏移相加得到物理地址。
分页减少了内存碎片,并提高了内存交换效率。</p>
<p>问题4:介绍一下多级页表?</p>
<p>为解决简单分页导致的页表太大问题,采用多级页表。
比如将一级页表分成多个二级页表,二级页表上的页表项数减少。仅在需要时创建下级页表。
这样使用时分布在各级页表上的页表项数显著减少,节省了大量内存。</p>
<p>问题5:介绍一下TLB?</p>
<p>TLB即转换查询缓存。位于CPU和MMU之间。
可以缓存最近访问过的虚拟地址和物理地址的映射。
为解决多级页表导致的地址转换时间长的问题。
TLB的命中率高,能大大提高地址转换效率。</p>
<p>问题6:介绍一下Linux的内存管理方式?</p>
<p>Linux主要采用的是分页式内存管理。
但是由于x86处理器支持分段式和分页式内存管理,Linux不得不采用段式内存管理。
但是Linux会把所有的段基地址设为0,相当于屏蔽了分段,段只用于访问控制和保护。</p>
<p>问题7:介绍一下Linux虚拟地址空间的布局?</p>
<p>Linux虚拟地址空间分为:内核空间和用户空间。
用户空间分为:代码段、数据段、BSS段、堆区、文件映射区、栈区。</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2023-06-08</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/" data-title="阅读prompt"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/" data-title="阅读prompt"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/" data-title="阅读prompt"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://rosouly.github.io/rosy.github.io/posts/%E9%98%85%E8%AF%BBprompt/" data-title="阅读prompt"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/rosy.github.io/">Home</a></span>
        </section>
    </div>

    <div class="post-nav">
            <a href="/rosy.github.io/posts/my-first-post/" class="next" rel="next" title="基于hugo&#43;github page搭建博客">基于hugo+github page搭建博客<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.111.3">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/rosy.github.io/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{}};</script><script type="text/javascript" src="/rosy.github.io/js/theme.min.js"></script></body>
</html>
